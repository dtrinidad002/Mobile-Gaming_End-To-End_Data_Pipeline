{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1db39817",
   "metadata": {},
   "source": [
    "# Understanding User Behavior For Mobile Gaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56172f9",
   "metadata": {},
   "source": [
    "Author: David Trinidad  \n",
    "MIDS W205 Data Engineering  \n",
    "Project 3  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee32eae",
   "metadata": {},
   "source": [
    "### Part I: Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187d536c",
   "metadata": {},
   "source": [
    "The intention of this project is to demonstrate a basic pipeline for collecting user metadata within the mobile-gaming space. We will step through the process where data from a Flask web server will publish into Kafka where the messages will be ingested into Spark, and finish off by saving the data into a Hadoop file system (HDFS) where basic analytical quiries can be conducted to answer business questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3096146b",
   "metadata": {},
   "source": [
    "**Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f7abef",
   "metadata": {},
   "source": [
    "As a Data Scientist of a gaming company, we take the scenario of tracking two events; \"purchasing a sword\" and \"joining a guild\". We assume these events are generated by a web interface of some sort. Below are the following tasks that will be highlighted during the step by step implementation process in section 3. \n",
    "\n",
    "**Tasks**  \n",
    "- 1. Instrument API server to log events to Kafka: The web server will be used to log the events where users buy a sword or join guild as json messages. \n",
    "- 2. Assemble a data pipeline to catch these events: use Spark streaming to filter select event types from Kafka, land them into HDFS/parquet to make them available for analysis using Presto.  \n",
    "- 3. Use Apache Bench to generate test data for your pipeline.  \n",
    "- 4. Produce an analytics report providing a description of your pipeline and some basic analysis of the events. Explaining the pipeline is key for this project!  \n",
    "\n",
    "**Files**\n",
    "\n",
    "- **Report.md**: This file is the writeup with step-by-step command annotations.\n",
    "- **docker-compose.yml**: Contains the cluster configuration\n",
    "- **mobileGame_api.py**: Python API for the Web Server.\n",
    "- **separate_events.py**: Python spark scripts to separate game event messages.\n",
    "- **event_filtering.py**: Python spark scripts to filter game event messages.\n",
    "- **filtered_writes.py**: is the Python spark scripts to save game event messages to file after filtering.\n",
    "- **JupyterQuery.ipynb**: Jupyter Notebook to save demonstrate queries from saved data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db606e5f",
   "metadata": {},
   "source": [
    "### Part II: Data Pipeline Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef85011",
   "metadata": {},
   "source": [
    "![](gaming_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a7b78f",
   "metadata": {},
   "source": [
    "### Part III: Step By Step Implementation Process "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d457c6",
   "metadata": {},
   "source": [
    "**step 1: Create project directory**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d3c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make project directory \n",
    "mkdir -p w205/project_3\n",
    "\n",
    "## Copy docker compose file from week 13 w205 course content\n",
    "cp ~/w205/course-content//13-Querying-Data/docker-compose.yml .\n",
    "cat docker-compose.yml"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a076127",
   "metadata": {},
   "source": [
    "jupyter@python-20210907-215615:~/w205$ cp ../w205/course-content/13-Understanding-Data/docker-compose.yml .\n",
    "jupyter@python-20210907-215615:~/w205$ cat docker-compose.yml  \n",
    "---\n",
    "version: '2'  \n",
    "services:  \n",
    "  zookeeper:  \n",
    "    image: confluentinc/cp-zookeeper:latest  \n",
    "    environment:  \n",
    "      ZOOKEEPER_CLIENT_PORT: 32181  \n",
    "      ZOOKEEPER_TICK_TIME: 2000  \n",
    "    expose:  \n",
    "      - \"2181\"  \n",
    "      - \"2888\"  \n",
    "      - \"32181\"  \n",
    "      - \"3888\"  \n",
    "    extra_hosts:  \n",
    "      - \"moby:127.0.0.1\"  \n",
    "  \n",
    "  kafka:  \n",
    "    image: confluentinc/cp-kafka:latest  \n",
    "    depends_on:  \n",
    "      - zookeeper  \n",
    "    environment:  \n",
    "      KAFKA_BROKER_ID: 1  \n",
    "      KAFKA_ZOOKEEPER_CONNECT: zookeeper:32181  \n",
    "      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092  \n",
    "      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1  \n",
    "    expose:  \n",
    "      - \"9092\"  \n",
    "      - \"29092\"  \n",
    "    extra_hosts:  \n",
    "      - \"moby:127.0.0.1\"  \n",
    "   \n",
    "  cloudera:  \n",
    "    image: midsw205/cdh-minimal:latest  \n",
    "    expose:  \n",
    "      - \"8020\" # nn  \n",
    "      - \"50070\" # nn http  \n",
    "      - \"8888\" # hue  \n",
    "    #ports:   \n",
    "    #- \"8888:8888\"  \n",
    "    extra_hosts:  \n",
    "      - \"moby:127.0.0.1\"  \n",
    "\n",
    "  spark:  \n",
    "    image: midsw205/spark-python:0.0.5  \n",
    "    stdin_open: true  \n",
    "    tty: true  \n",
    "    volumes:  \n",
    "      - ~/w205:/w205  \n",
    "    expose:  \n",
    "      - \"8888\"  \n",
    "    ports:  \n",
    "      - \"8888:8888\"  \n",
    "    depends_on:  \n",
    "      - cloudera  \n",
    "    environment:  \n",
    "      HADOOP_NAMENODE: cloudera  \n",
    "    extra_hosts:  \n",
    "      - \"moby:127.0.0.1\"  \n",
    "    command: bash  \n",
    "  \n",
    "  mids:  \n",
    "    image: midsw205/base:0.1.9  \n",
    "    stdin_open: true  \n",
    "    tty: true  \n",
    "    volumes:  \n",
    "      - ~/w205:/w205  \n",
    "    expose:  \n",
    "      - \"5000\"  \n",
    "    ports:  \n",
    "      - \"5000:5000\"  \n",
    "    extra_hosts:  \n",
    "      - \"moby:127.0.0.1\"  \n",
    "jupyter@python-20210907-215615:~/w205$   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdad031",
   "metadata": {},
   "source": [
    "**step 2: Execute docker container**\n",
    "\n",
    "Services within the docker cluster include kafka, zookeeper, saprk and mids. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10b9e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spin up docker cluster\n",
    "docker-compose up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90a800b",
   "metadata": {},
   "source": [
    "jupyter@python-20210907-215615:~/w205/w205/project_3$ docker-compose ps\n",
    "        Name                       Command                State                      Ports                  \n",
    "------------------------------------------------------------------------------------------------------------\n",
    "project_3_cloudera_1    /usr/bin/docker-entrypoint ...   Exit 139                                           \n",
    "project_3_kafka_1       /etc/confluent/docker/run        Up         29092/tcp, 9092/tcp                     \n",
    "project_3_mids_1        /bin/bash                        Up         8888/tcp                                \n",
    "project_3_presto_1      /usr/bin/docker-entrypoint ...   Up         8080/tcp                                \n",
    "project_3_spark_1       docker-entrypoint.sh bash        Up         0.0.0.0:8889->8888/tcp,:::8889->8888/tcp\n",
    "project_3_zookeeper_1   /etc/confluent/docker/run        Up         2181/tcp, 2888/tcp, 32181/tcp, 3888/tcp \n",
    "jupyter@python-20210907-215615:~/w205/w205/project_3$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470b8b99",
   "metadata": {},
   "source": [
    "**step 3: set up logs for hadoop and kafka**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7212a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up monitor log for hadoop\n",
    "docker-compose logs -f cloudera\n",
    "\n",
    "#set up monitor log for kafka\n",
    "docker-compose logs -f kafka\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c710805",
   "metadata": {},
   "outputs": [],
   "source": [
    "Attaching to project_3_cloudera_1\n",
    "project_3_cloudera_1 exited with code 139"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ed7a105",
   "metadata": {},
   "source": [
    "jupyter@python-20210907-215615:~/w205/w205/project_3$ docker-compose exec cloudera hadoop fs -ls /tmp/\n",
    "Found 2 items\n",
    "drwxrwxrwt   - mapred mapred              0 2021-02-06 18:27 /tmp/hadoop-yarn\n",
    "drwx-wx-wx   - root   supergroup          0 2021-07-21 16:09 /tmp/hive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b1ee2e",
   "metadata": {},
   "source": [
    "**step 4: Create Kafka topic \"Events\"**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58261d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker-compose exec kafka "
   ]
  },
  {
   "cell_type": "raw",
   "id": "b312ac7f",
   "metadata": {},
   "source": [
    "\n",
    "jupyter@python-20210907-215615:~/w205/w205/project_3$ docker-compose exec kafka \\\n",
    ">    kafka-topics \\\n",
    ">      --create \\\n",
    ">      --topic events \\\n",
    ">      --partitions 1 \\\n",
    ">      --replication-factor 1 \\\n",
    ">      --if-not-exists \\\n",
    ">      --zookeeper zookeeper:32181\n",
    "Created topic \"events\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec033910",
   "metadata": {},
   "source": [
    "**step 5: Create the Web API (mobileGame_api.py)**\n",
    "\n",
    "Below is the  mobileGame_api.py file. (This script was modified from the example from week 13 async)The code contains two Web API calls;1. buy_sword and join_guild. Both use the json to log the events to kafka. Moreover, meta data from user request was also added to the event logging. Finally, I enhanced the API to allow parameters in purchase_a_sword Web API."
   ]
  },
  {
   "cell_type": "raw",
   "id": "fcbbbf80",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"Mobile Gaming API Web Calls\"\"\"\n",
    "\n",
    "import json\n",
    "from kafka import KafkaProducer\n",
    "from flask import Flask, request\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "event_logger = KafkaProducer(bootstrap_servers='kafka:29092')\n",
    "events_topic = 'events'\n",
    "\n",
    "def log_to_kafka(topic, event):\n",
    "    event.update(request.headers)\n",
    "    producer.send(topic, json.dumps(event).encode())\n",
    "\n",
    "##Web call for joining guild event#    \n",
    "@app.route(\"/join_guild\")\n",
    "def join_guild():\n",
    "    join_guild_event = {'event_type': 'join_guild'}\n",
    "    log_to_kafka(events_topic, join_guild_event)\n",
    "    return \"\\nGuild joined!\\n\"\n",
    "\n",
    "##Web call for purchase sword event#     \n",
    "@app.route(\"/purchase_sword\")\n",
    "def purchase_sword():\n",
    "    buy_sword_event = {'event_type': 'purchase_sword'}\n",
    "    sword_parameter = request.args.to_dict()\n",
    "    buy_sword_event.update(sword_parameter)\n",
    "    log_to_kafka(events_topic, buy_sword_event)\n",
    "    return \"\\nSword Purchased!\\n\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ecc3a9",
   "metadata": {},
   "source": [
    "**step 6: Run Flask**  \n",
    "- Run flask withthe mobileGame_api.py\n",
    "- launch the flask web server "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60798eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Code\n",
    "docker-compose exec mids env FLASK_APP=/w205/project_3/mobileGame_api.py flask run --host 0.0.0.0"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb4a8258",
   "metadata": {},
   "source": [
    "\n",
    "jupyter@python-20210907-215615:~/w205/w205/project_3$ docker-compose exec mids env FLASK_APP=/w205/project_3/mobileGame_api.py flask run --host 0.0.0.0\n",
    "* Serving Flask app \"game_api\"\n",
    " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n",
    "127.0.0.1 - - [11/Dec/2021 20:16:27] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:16:27] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:16:27] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:16:27] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:16:27] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:16:27] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:16:27] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:16:27] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:16:27] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:16:27] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:17:32] \"GET /join_guild HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:17:32] \"GET /join_guild HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:17:32] \"GET /join_guild HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:17:32] \"GET /join_guild HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:17:32] \"GET /join_guild HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:17:32] \"GET /join_guild HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:17:32] \"GET /join_guild HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:17:32] \"GET /join_guild HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:17:32] \"GET /join_guild HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:17:32] \"GET /join_guild HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:17:24] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:17:25] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:17:25] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:17:25] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:17:25] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:17:25] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:17:25] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:17:25] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:17:25] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:17:25] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:19:13] \"GET /join_guild HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:19:13] \"GET /join_guild HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:19:13] \"GET /join_guild HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:19:13] \"GET /join_guild HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:19:13] \"GET /join_guild HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:19:13] \"GET /join_guild HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:19:13] \"GET /join_guild HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:19:13] \"GET /join_guild HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:19:13] \"GET /join_guild HTTP/1.0\" 200 -\n",
    "127.0.0.1 - - [11/Dec/2021 20:19:13] \"GET /join_guild HTTP/1.0\" 200 -\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6630a2e",
   "metadata": {},
   "source": [
    "**step 7: Apache Bench to generate data (**  \n",
    "Utilizing a different terminal, below you can see Apache bench commands to generate Web API buy_a_sword and join_guild calls. Note that the output from the flask server matches with Apache bench commands."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b0d72bb",
   "metadata": {},
   "source": [
    "jupyter@python-20210907-215615:~/w205/w205/project_3$ docker-compose exec mids ab -n 10 -H \"Host: user1.comcast.com\" http://localhost:5000/buy_a_sword\n",
    "This is ApacheBench, Version 2.3 <$Revision: 1706008 $>\n",
    "Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/\n",
    "Licensed to The Apache Software Foundation, http://www.apache.org/\n",
    "\n",
    "Benchmarking localhost (be patient).....done\n",
    "\n",
    "\n",
    "Server Software:        Werkzeug/0.14.1\n",
    "Server Hostname:        localhost\n",
    "Server Port:            5000\n",
    "\n",
    "Document Path:          /purchase_a_sword\n",
    "Document Length:        18 bytes\n",
    "\n",
    "Concurrency Level:      1\n",
    "Time taken for tests:   0.028 seconds\n",
    "Complete requests:      10\n",
    "Failed requests:        0\n",
    "Total transferred:      1730 bytes\n",
    "HTML transferred:       180 bytes\n",
    "Requests per second:    362.31 [#/sec] (mean)\n",
    "Time per request:       2.760 [ms] (mean)\n",
    "Time per request:       2.760 [ms] (mean, across all concurrent requests)\n",
    "Transfer rate:          61.21 [Kbytes/sec] received\n",
    "\n",
    "Connection Times (ms)\n",
    "              min  mean[+/-sd] median   max\n",
    "Connect:        0    0   0.1      0       0\n",
    "Processing:     1    3   3.6      2      13\n",
    "Waiting:        0    2   3.8      1      12\n",
    "Total:          1    3   3.6      2      13\n",
    "\n",
    "Percentage of the requests served within a certain time (ms)\n",
    "  50%      2\n",
    "  66%      2\n",
    "  75%      2\n",
    "  80%      2\n",
    "  90%     13\n",
    "  95%     13\n",
    "  98%     13\n",
    "  99%     13\n",
    " 100%     13 (longest request)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da3f90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user1.comcast.com\" http://localhost:5000/join_guild"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d3aead0",
   "metadata": {},
   "source": [
    "jupyter@python-20210907-215615:~/w205/w205/project_3$ docker-compose exec mids ab -n 10 -H \"Host: user1.comcast.com\" http://localhost:5000/join_guild\n",
    "This is ApacheBench, Version 2.3 <$Revision: 1706008 $>\n",
    "Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/\n",
    "Licensed to The Apache Software Foundation, http://www.apache.org/\n",
    "\n",
    "Benchmarking localhost (be patient).....done\n",
    "\n",
    "\n",
    "Server Software:        Werkzeug/0.14.1\n",
    "Server Hostname:        localhost\n",
    "Server Port:            5000\n",
    "\n",
    "Document Path:          /join_guild\n",
    "Document Length:        15 bytes\n",
    "\n",
    "Concurrency Level:      1\n",
    "Time taken for tests:   0.049 seconds\n",
    "Complete requests:      10\n",
    "Failed requests:        0\n",
    "Total transferred:      1700 bytes\n",
    "HTML transferred:       150 bytes\n",
    "Requests per second:    206.04 [#/sec] (mean)\n",
    "Time per request:       4.854 [ms] (mean)\n",
    "Time per request:       4.854 [ms] (mean, across all concurrent requests)\n",
    "Transfer rate:          34.21 [Kbytes/sec] received\n",
    "\n",
    "Connection Times (ms)\n",
    "              min  mean[+/-sd] median   max\n",
    "Connect:        0    0   0.3      0       1\n",
    "Processing:     2    5   2.6      5      10\n",
    "Waiting:        0    4   3.2      4      10\n",
    "Total:          2    5   2.5      5      10\n",
    "\n",
    "Percentage of the requests served within a certain time (ms)\n",
    "  50%      5\n",
    "  66%      5\n",
    "  75%      6\n",
    "  80%      8\n",
    "  90%     10\n",
    "  95%     10\n",
    "  98%     10\n",
    "  99%     10\n",
    " 100%     10 (longest request)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f714df5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user2.att.com\" http://localhost:5000/purchase_a_sword"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf8ea348",
   "metadata": {},
   "source": [
    "jupyter@python-20210907-215615:~/w205/w205/project_3$  docker-compose exec mids ab -n 10 -H \"Host: user2.att.com\" http://localhost:5000/purchase_a_sword\n",
    "This is ApacheBench, Version 2.3 <$Revision: 1706008 $>\n",
    "Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/\n",
    "Licensed to The Apache Software Foundation, http://www.apache.org/\n",
    "\n",
    "Benchmarking localhost (be patient).....done\n",
    "\n",
    "\n",
    "Server Software:        Werkzeug/0.14.1\n",
    "Server Hostname:        localhost\n",
    "Server Port:            5000\n",
    "\n",
    "Document Path:          /purchase_a_sword\n",
    "Document Length:        18 bytes\n",
    "\n",
    "Concurrency Level:      1\n",
    "Time taken for tests:   0.045 seconds\n",
    "Complete requests:      10\n",
    "Failed requests:        0\n",
    "Total transferred:      1730 bytes\n",
    "HTML transferred:       180 bytes\n",
    "Requests per second:    222.90 [#/sec] (mean)\n",
    "Time per request:       4.486 [ms] (mean)\n",
    "Time per request:       4.486 [ms] (mean, across all concurrent requests)\n",
    "Transfer rate:          37.66 [Kbytes/sec] received\n",
    "\n",
    "Connection Times (ms)\n",
    "              min  mean[+/-sd] median   max\n",
    "Connect:        0    0   0.0      0       0\n",
    "Processing:     2    4   3.5      4      11\n",
    "Waiting:        1    4   3.6      2      11\n",
    "Total:          2    4   3.5      4      11\n",
    "\n",
    "Percentage of the requests served within a certain time (ms)\n",
    "  50%      4\n",
    "  66%      4\n",
    "  75%      6\n",
    "  80%     10\n",
    "  90%     11\n",
    "  95%     11\n",
    "  98%     11\n",
    "  99%     11\n",
    " 100%     11 (longest request)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdf6510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user2.att.com\" http://localhost:5000/join_guild"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ba51ce0f",
   "metadata": {},
   "source": [
    "jupyter@python-20210907-215615:~/w205/w205/project_3$ docker-compose exec mids ab -n 10 -H \"Host: user2.att.com\" http://localhost:5000/join_guild\n",
    "This is ApacheBench, Version 2.3 <$Revision: 1706008 $>\n",
    "Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/\n",
    "Licensed to The Apache Software Foundation, http://www.apache.org/\n",
    "\n",
    "Benchmarking localhost (be patient).....done\n",
    "\n",
    "\n",
    "Server Software:        Werkzeug/0.14.1\n",
    "Server Hostname:        localhost\n",
    "Server Port:            5000\n",
    "\n",
    "Document Path:          /join_guild\n",
    "Document Length:        15 bytes\n",
    "\n",
    "Concurrency Level:      1\n",
    "Time taken for tests:   0.056 seconds\n",
    "Complete requests:      10\n",
    "Failed requests:        0\n",
    "Total transferred:      1700 bytes\n",
    "HTML transferred:       150 bytes\n",
    "Requests per second:    177.58 [#/sec] (mean)\n",
    "Time per request:       5.631 [ms] (mean)\n",
    "Time per request:       5.631 [ms] (mean, across all concurrent requests)\n",
    "Transfer rate:          29.48 [Kbytes/sec] received\n",
    "\n",
    "Connection Times (ms)\n",
    "              min  mean[+/-sd] median   max\n",
    "Connect:        0    0   0.1      0       0\n",
    "Processing:     3    6   2.7      6      10\n",
    "Waiting:        0    3   2.1      3       6\n",
    "Total:          3    6   2.7      6      11\n",
    "\n",
    "Percentage of the requests served within a certain time (ms)\n",
    "  50%      6\n",
    "  66%      6\n",
    "  75%      7\n",
    "  80%      9\n",
    "  90%     11\n",
    "  95%     11\n",
    "  98%     11\n",
    "  99%     11\n",
    " 100%     11 (longest request)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928d4af5",
   "metadata": {},
   "source": [
    "**step 8: Used kafkacat to monitor streaming messages into kafka**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54069adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## monitor events into kafka port 29092\n",
    "docker-compose exec mids kafkacat -C -b kafka:29092 -t events -o beginning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "faacdf77",
   "metadata": {},
   "source": [
    "jupyter@python-20210907-215615:~/w205/w205/project_3$ docker-compose exec mids kafkacat -C -b kafka:29092 -t events -o beginning\n",
    "{\"Host\": \"user1.comcast.com\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user1.comcast.com\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user1.comcast.com\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user1.comcast.com\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user1.comcast.com\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user1.comcast.com\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user1.comcast.com\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user1.comcast.com\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user1.comcast.com\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user1.comcast.com\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user1.comcast.com\", \"event_type\": \"join_guild\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user1.comcast.com\", \"event_type\": \"join_guild\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user1.comcast.com\", \"event_type\": \"join_guild\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user1.comcast.com\", \"event_type\": \"join_guild\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user1.comcast.com\", \"event_type\": \"join_guild\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user1.comcast.com\", \"event_type\": \"join_guild\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user1.comcast.com\", \"event_type\": \"join_guild\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user1.comcast.com\", \"event_type\": \"join_guild\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user1.comcast.com\", \"event_type\": \"join_guild\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user1.comcast.com\", \"event_type\": \"join_guild\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user2.att.com\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user2.att.com\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user2.att.com\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user2.att.com\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user2.att.com\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user2.att.com\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user2.att.com\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user2.att.com\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user2.att.com\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user2.att.com\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user2.att.com\", \"event_type\": \"join_guild\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user2.att.com\", \"event_type\": \"join_guild\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user2.att.com\", \"event_type\": \"join_guild\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user2.att.com\", \"event_type\": \"join_guild\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user2.att.com\", \"event_type\": \"join_guild\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user2.att.com\", \"event_type\": \"join_guild\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user2.att.com\", \"event_type\": \"join_guild\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user2.att.com\", \"event_type\": \"join_guild\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user2.att.com\", \"event_type\": \"join_guild\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}\n",
    "{\"Host\": \"user2.att.com\", \"event_type\": \"join_guild\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee04e73d",
   "metadata": {},
   "source": [
    "**step 9:** filter kafka events  \n",
    "\n",
    "- below is the event_filtering script for filtering the kafka events for \"purchase_sword\" and \"join_guild\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b0e2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"Python Spark Script for filtering event messages\"\"\"\n",
    "\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import udf\n",
    "import json\n",
    "\n",
    "@udf('boolean')\n",
    "def is_purchase(event_as_json):\n",
    "    event = json.loads(event_as_json)\n",
    "    if event['event_type'] == 'purchase_sword':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"main\"\"\"\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"ExtractEventsJob\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    events_raw = spark \\\n",
    "        .read \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "        .option(\"subscribe\", \"events\") \\\n",
    "        .option(\"startingOffsets\", \"earliest\") \\\n",
    "        .option(\"endingOffsets\", \"latest\") \\\n",
    "        .load()\n",
    "\n",
    "    event_purchases = events_raw \\\n",
    "        .select(events_raw.value.cast('string').alias('raw'),\n",
    "                events_raw.timestamp.cast('string')) \\\n",
    "        .filter(is_purchase('raw'))\n",
    "\n",
    "    event_purchases_extracted = event_purchases \\\n",
    "        .rdd \\\n",
    "        .map(lambda r: Row(timestamp=r.timestamp, **json.loads(r.raw))) \\\n",
    "        .toDF()\n",
    "    event_purchases_extracted.printSchema()\n",
    "    event_purchases_extracted.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b2508f",
   "metadata": {},
   "source": [
    "**step 10:** execute Spark service container with the filtering.py script\n",
    "\n",
    "- For readability portions of the output was condensed or left out. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33eea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "##code\n",
    "docker-compose exec spark spark-submit /w205/project_3/event_filtering.py\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c3945df",
   "metadata": {},
   "source": [
    "jupyter@python-20210907-215615:~/w205/w205/project_3$ docker-compose exec spark spark-submit /w205/project_3/event_filtering.py\n",
    "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
    "21/12/11 21:15:50 INFO SparkContext: Running Spark version 2.2.0\n",
    "\n",
    "###Output Condensed###\n",
    "\n",
    "21/12/11 21:16:11 INFO DAGScheduler: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 0.259 s\n",
    "21/12/11 21:16:11 INFO DAGScheduler: Job 1 finished: showString at NativeMethodAccessorImpl.java:0, took 0.287336 s\n",
    "21/12/11 21:16:12 INFO CodeGenerator: Code generated in 16.815289 ms\n",
    "+------+-----------------+---------------+--------------+--------------------+\n",
    "|Accept|             Host|     User-Agent|    event_type|           timestamp|\n",
    "+------+-----------------+---------------+--------------+--------------------+\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-11 20:40:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-11 20:40:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-11 20:40:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-11 20:40:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-11 20:40:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-11 20:40:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-11 20:40:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-11 20:40:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-11 20:40:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-11 20:40:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|2021-12-11 20:40:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|2021-12-11 20:40:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|2021-12-11 20:40:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|2021-12-11 20:40:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|2021-12-11 20:40:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|2021-12-11 20:40:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|2021-12-11 20:40:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|2021-12-11 20:40:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|2021-12-11 20:40:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|2021-12-11 20:40:...|\n",
    "+------+-----------------+---------------+--------------+--------------------+\n",
    "\n",
    "21/12/11 21:16:12 INFO ConsumerConfig: ConsumerConfig values: \n",
    "    metric.reporters = []\n",
    "    metadata.max.age.ms = 300000\n",
    "    partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]\n",
    "    reconnect.backoff.ms = 50\n",
    "    sasl.kerberos.ticket.renew.window.factor = 0.8\n",
    "    max.partition.fetch.bytes = 1048576\n",
    "    bootstrap.servers = [kafka:29092] \n",
    "\n",
    "\n",
    "######Output Condensed#######\n",
    "\n",
    "21/12/11 21:16:17 INFO PythonRunner: Times: total = 25, boot = 9, init = 14, finish = 2\n",
    "21/12/11 21:16:17  INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2193 bytes result sent to driver\n",
    "21/12/11 21:16:17  INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 236 ms on localhost (executor driver) (1/1)\n",
    "21/12/11 21:16:17  INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool \n",
    "21/12/11 21:16:17  INFO DAGScheduler: ResultStage 3 (showString at NativeMethodAccessorImpl.java:0) finished in 0.436 s\n",
    "21/12/11 21:16:17  INFO DAGScheduler: Job 3 finished: showString at NativeMethodAccessorImpl.java:0, took 0.420573 s\n",
    "+------+-----------------+---------------+----------+--------------------+\n",
    "|Accept|             Host|     User-Agent|event_type|           timestamp|\n",
    "+------+-----------------+---------------+----------+--------------------+\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|2021-12-11 20:43:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|2021-12-11 20:43:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|2021-12-11 20:43:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|2021-12-11 20:43:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|2021-12-11 20:43:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|2021-12-11 20:43:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|2021-12-11 20:43:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|2021-12-11 20:43:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|2021-12-11 20:43:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|2021-12-11 20:43:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|2021-12-11 20:43:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|2021-12-11 20:43:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|2021-12-11 20:43:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|2021-12-11 20:43:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|2021-12-11 20:43:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|2021-12-11 20:43:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|2021-12-11 20:43:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|2021-12-11 20:43:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|2021-12-11 20:43:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|2021-12-11 20:43:...|\n",
    "+------+-----------------+---------------+----------+--------------------+\n",
    "\n",
    "21/12/11 21:16:18 INFO SparkContext: Invoking stop() from shutdown hook\n",
    "21/12/11 21:16:18 INFO SparkUI: Stopped Spark web UI at http://172.18.0.6:4040\n",
    "21/12/11 21:16:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
    "21/12/11 21:16:18 INFO MemoryStore: MemoryStore cleared\n",
    "21/12/11 21:16:18 INFO BlockManager: BlockManager stopped\n",
    "21/12/11 21:16:18 INFO BlockManagerMaster: BlockManagerMaster stopped\n",
    "21/12/11 21:16:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
    "21/12/11 21:16:18 INFO SparkContext: Successfully stopped SparkContext\n",
    "21/12/11 21:16:18 INFO ShutdownHookManager: Shutdown hook called\n",
    "21/12/11 21:16:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-08facf7d-515b-4a79-93b9-114c83621df9/pyspark-564952cf-792a-4ddc-9953-e949a542ad9a\n",
    "21/12/11 21:16:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-08facf7d-515b-4a79-93b9-114c83621df9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5130c4d7",
   "metadata": {},
   "source": [
    "**Step 11: Write filtered events from Kafka into HDFS**   \n",
    "\n",
    "- below is the script for \"**filtered_writes.py**\" which will take the events from Kafka and filter them for \"purchase_sword\" and \"join_guild\"\n",
    "- note, the filtered write script was slightly modified from the the example in week 13. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12902b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"Python spark script for saving filtered events\"\"\"\n",
    "\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import udf\n",
    "import json\n",
    "\n",
    "@udf('boolean')\n",
    "def is_purchase(event_as_json):\n",
    "    event = json.loads(event_as_json)\n",
    "    if event['event_type'] == 'purchase_sword':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"main\"\"\"\n",
    "    \n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"ExtractEventsJob\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    events_raw = spark \\\n",
    "        .read \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "        .option(\"subscribe\", \"events\") \\\n",
    "        .option(\"startingOffsets\", \"earliest\") \\\n",
    "        .option(\"endingOffsets\", \"latest\") \\\n",
    "        .load()\n",
    "\n",
    "    event_purchases = events_raw \\\n",
    "        .select(events_raw.value.cast('string').alias('raw'),\n",
    "                events_raw.timestamp.cast('string')) \\\n",
    "        .filter(is_purchase('raw'))\n",
    "\n",
    "    event_joinGuild = events_raw \\\n",
    "        .select(raw_events.value.cast('string').alias('raw'),\n",
    "                raw_events.timestamp.cast('string')) \\\n",
    "        .filter(is_joinguild('raw'))\n",
    "    \n",
    "    event_purchases_extracted = event_purchases \\\n",
    "        .rdd \\\n",
    "        .map(lambda r: Row(timestamp=r.timestamp, **json.loads(r.raw))) \\\n",
    "        .toDF()\n",
    "    event_purchases_extracted.printSchema()\n",
    "    event_purchases_extracted.show()\n",
    "\n",
    "    events_joinGuild_extracted = event_joinguild \\\n",
    "        .rdd \\\n",
    "        .map(lambda r: Row(timestamp=r.timestamp, **json.loads(r.raw))) \\\n",
    "        .toDF()\n",
    "    event_joinGuild_extracted.printSchema()\n",
    "    event_joinGuild_extracted.show()\n",
    "    \n",
    "    event_purchases_extracted \\\n",
    "        .write \\\n",
    "        .mode('overwrite') \\\n",
    "        .parquet('/tmp/purchases')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8355553",
   "metadata": {},
   "source": [
    "**step 12:** Execute the filtered_writes.py script with Spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd5e4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Code\n",
    "docker-compose exec spark spark-submit /w205/prj3/filtered_writes.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b94d699",
   "metadata": {},
   "source": [
    "**step 13:** check parquet files in hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78710b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code\n",
    "docker-compose exec cloudera hadoop fs -ls /tmp/\n",
    "\n",
    "#check sword purchases are written into hdfs\n",
    "docker-compose exec cloudera hadoop fs -ls /tmp/purchases\n",
    "\n",
    "#check join guilds events written to hdfs\n",
    "docker-compose exec cloudera hadoop fs -ls /tmp/joinguilds"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f72fa251",
   "metadata": {},
   "source": [
    "jupyter@python-20210907-215615:~/w205/w205/project_3$ docker-compose exec cloudera hadoop fs -ls /tmp/\n",
    "Found 4 items\n",
    "drwxrwxrwt   - mapred mapred              0 2021-12-11 21:23 /tmp/hadoop-yarn\n",
    "drwx-wx-wx   - root   supergroup          0 2021-12-11 21:31 /tmp/hive\n",
    "drwxr-xr-x   - root   supergroup          0 2021-12-11 22:29 /tmp/joinguilds\n",
    "drwxr-xr-x   - root   supergroup          0 2021-12-11 22:29 /tmp/purchases"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f1d0a00a",
   "metadata": {},
   "source": [
    "jupyter@python-20210907-215615:~/w205/w205/project_3$ docker-compose exec cloudera hadoop fs -ls /tmp/purchases\n",
    "Found 2 items\n",
    "-rw-r--r--   1 root supergroup          0 2021-12-11 22:29 /tmp/purchases/_SUCCESS\n",
    "-rw-r--r--   1 root supergroup       1643 2021-12-11 22:29 /tmp/purchases/part-00000-7ab1d0ba-6e90-4386-9afd-2772df166afb-c000.snappy.parquet\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ff02ea4",
   "metadata": {},
   "source": [
    "jupyter@python-20210907-215615:~/w205/w205/project_3$ docker-compose exec cloudera hadoop fs -ls /tmp/joinguilds\n",
    "Found 2 items\n",
    "-rw-r--r--   1 root supergroup          0 2021-12-11 22:29 /tmp/joinguilds/_SUCCESS\n",
    "-rw-r--r--   1 root supergroup       1630 2021-12-11 22:29 /tmp/joinguilds/part-00000-9edfa102-881a-46fd-a303-641c88e0e6fc-c000.snappy.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8adfad",
   "metadata": {},
   "source": [
    "**step 14:** Spin up Jupyter Notebook and run quiries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486e6e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "##code\n",
    "docker-compose exec spark env PYSPARK_DRIVER_PYTHON=jupyter PYSPARK_DRIVER_PYTHON_OPTS='notebook --no-browser --port 8888 --ip 0.0.0.0 --allow-root' pyspark"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50c08717",
   "metadata": {},
   "source": [
    "jupyter@python-20210907-215615:~/w205/w205/project_3$ docker-compose exec spark env PYSPARK_DRIVER_PYTHON=jupyter PYSPARK_DRIVER_PYTHON_OPTS='notebook --no-browser --port 8888 --ip 0.0.0.0 --allow-root' pyspark\n",
    "[I 06:54:22.585 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret\n",
    "[I 06:54:22.706 NotebookApp] Serving notebooks from local directory: /spark-2.2.0-bin-hadoop2.6\n",
    "[I 06:54:22.708 NotebookApp] 0 active kernels \n",
    "[I 06:54:22.709 NotebookApp] The Jupyter Notebook is running at: http://0.0.0.0:8888/?token=6f05e881994c8c2bee7cb08bdd7f309d776ded466e0e5694\n",
    "[I 06:54:22.711 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n",
    "[C 06:54:22.712 NotebookApp] \n",
    "    \n",
    "    Copy/paste this URL into your browser when you connect for the first time,\n",
    "    to login with a token:\n",
    "        http://0.0.0.0:8888/?token=6f05e881994c8c2bee7cb08bdd7f309d776ded466e0e5694"
   ]
  },
  {
   "cell_type": "raw",
   "id": "376c3bd5",
   "metadata": {},
   "source": [
    "#Run spark bash \n",
    "docker-compose exec spark bash"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb5bd1c8",
   "metadata": {},
   "source": [
    "jupyter@python-20210907-215615:~/w205/w205/project_3$ docker-compose exec spark bash\n",
    "root@1044dc901d38:/spark-2.2.0-bin-hadoop2.6# ln -s /w205 w205\n",
    "root@1044dc901d38:/spark-2.2.0-bin-hadoop2.6# ls -tl \n",
    "total 100\n",
    "lrwxrwxrwx 1 root root     5 Dec 13 06:57 w205 -> /w205\n",
    "drwxr-xr-x 1  500  500  4096 Dec 13 05:18 conf\n",
    "lrwxrwxrwx 1 root root    34 Apr  3  2018 entrypoint.sh -> usr/local/bin/docker-entrypoint.sh\n",
    "drwxr-xr-x 1  500  500  4096 Apr  3  2018 jars\n",
    "drwxr-xr-x 2 root root  4096 Apr  3  2018 templates\n",
    "-rw-r--r-- 1  500  500 17881 Jun 30  2017 LICENSE\n",
    "drwxr-xr-x 3  500  500  4096 Jun 30  2017 R\n",
    "-rw-r--r-- 1  500  500  3809 Jun 30  2017 README.md\n",
    "-rw-r--r-- 1  500  500   128 Jun 30  2017 RELEASE\n",
    "drwxr-xr-x 2  500  500  4096 Jun 30  2017 bin\n",
    "drwxr-xr-x 5  500  500  4096 Jun 30  2017 data\n",
    "drwxr-xr-x 4  500  500  4096 Jun 30  2017 examples\n",
    "drwxr-xr-x 2  500  500  4096 Jun 30  2017 licenses\n",
    "drwxr-xr-x 6  500  500  4096 Jun 30  2017 python\n",
    "drwxr-xr-x 2  500  500  4096 Jun 30  2017 sbin\n",
    "drwxr-xr-x 2  500  500  4096 Jun 30  2017 yarn\n",
    "-rw-r--r-- 1  500  500 24645 Jun 30  2017 NOTICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7ae92c",
   "metadata": {},
   "source": [
    "**Step 15:** Querey Data from Spark Using Jupyter Notebooks\n",
    "\n",
    "-Quereying for sword purchases and joining guilds utilizing lesson from week 12  \n",
    "\n",
    "- **(the following were copied over from the working jupyter notebook)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b21e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchases = spark.read.parquet('/tmp/purchases')\n",
    "purchases.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6b13ec7",
   "metadata": {},
   "source": [
    "Accept|             Host|     User-Agent|    event_type|           timestamp|\n",
    "+------+-----------------+---------------+--------------+--------------------+\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:36:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:36:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:36:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:36:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:36:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:36:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:36:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:36:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:36:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:36:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:36:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:36:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:36:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:36:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:36:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:36:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:36:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:36:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:36:...|\n",
    "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:36:...|\n",
    "+------+-----------------+---------------+--------------+--------------------+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21656a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchases.registerTempTable('purchases')\n",
    "purchases_by_example2 = spark.sql(\"select * from purchases where Host = 'user1.comcast.com'\")\n",
    "purchases_by_example2.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "57033074",
   "metadata": {},
   "source": [
    "Accept|             Host|     User-Agent|    event_type|           timestamp|\n",
    "+------+-----------------+---------------+--------------+--------------------+\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:50:...|\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:50:...||\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:50:...||\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:50:...||\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:50:...||\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:50:...||\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:50:...||\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:50:...||\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:50:...||\n",
    "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2021-12-12 22:50:...||\n",
    "+------+-----------------+---------------+--------------+--------------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623a821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf1 = purchases_by_example2.toPandas()\n",
    "newdf1.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b265203",
   "metadata": {},
   "source": [
    "![](purchases.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027e266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_guilds = spark.read.parquet('/tmp/joinguilds')\n",
    "join_guilds.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7952de4",
   "metadata": {},
   "source": [
    "Accept|         Host|     User-Agent|event_type|           timestamp|\n",
    "+------+-------------+---------------+----------+--------------------+\n",
    "|   */*|user2.att.com|ApacheBench/2.3|join_guild|2021-12-12 24:39:...|\n",
    "|   */*|user2.att.com|ApacheBench/2.3|join_guild|2021-12-12 24:39:...|\n",
    "|   */*|user2.att.com|ApacheBench/2.3|join_guild|2021-12-12 24:39:...|\n",
    "|   */*|user2.att.com|ApacheBench/2.3|join_guild|2021-12-12 24:39:...|\n",
    "|   */*|user2.att.com|ApacheBench/2.3|join_guild|2021-12-12 24:39:...|\n",
    "|   */*|user2.att.com|ApacheBench/2.3|join_guild|2021-12-12 24:39:...|\n",
    "|   */*|user2.att.com|ApacheBench/2.3|join_guild|2021-12-12 24:39:...|\n",
    "|   */*|user2.att.com|ApacheBench/2.3|join_guild|2021-12-12 24:39:...|\n",
    "|   */*|user2.att.com|ApacheBench/2.3|join_guild|2021-12-12 24:39:...|\n",
    "|   */*|user2.att.com|ApacheBench/2.3|join_guild|2021-12-12 24:39:...|\n",
    "+------+-------------+---------------+----------+--------------------+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1004bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_guilds_example = spark.sql(\"select * from joinguilds where Host = 'user2.att.com'\")\n",
    "join_guilds_example.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8f29260",
   "metadata": {},
   "source": [
    "+------+-------------+---------------+----------+--------------------+\n",
    "|Accept|         Host|     User-Agent|event_type|           timestamp|\n",
    "+------+-------------+---------------+----------+--------------------+\n",
    "|   */*|user2.att.com|ApacheBench/2.3|join_guild|2021-12-12 24:50:...|\n",
    "|   */*|user2.att.com|ApacheBench/2.3|join_guild|2021-12-12 24:50:...|\n",
    "|   */*|user2.att.com|ApacheBench/2.3|join_guild|2021-12-12 24:50:...|\n",
    "|   */*|user2.att.com|ApacheBench/2.3|join_guild|2021-12-12 24:50:...|\n",
    "|   */*|user2.att.com|ApacheBench/2.3|join_guild|2021-12-12 24:50:...|\n",
    "|   */*|user2.att.com|ApacheBench/2.3|join_guild|2021-12-12 24:50:...|\n",
    "|   */*|user2.att.com|ApacheBench/2.3|join_guild|2021-12-12 24:50:...|\n",
    "|   */*|user2.att.com|ApacheBench/2.3|join_guild|2021-12-12 24:50:...|\n",
    "|   */*|user2.att.com|ApacheBench/2.3|join_guild|2021-12-12 24:50:...|\n",
    "|   */*|user2.att.com|ApacheBench/2.3|join_guild|2021-12-12 24:50:...|\n",
    "+------+-------------+---------------+----------+--------------------+\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a9e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf2 = join_guilds_example.toPandas()\n",
    "newdf2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98cd4d2",
   "metadata": {},
   "source": [
    "![](guild.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e8aa89",
   "metadata": {},
   "source": [
    "## Part IV Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a7e0c4",
   "metadata": {},
   "source": [
    "In this project, we successfully demonstrated how to track two game events through a web surver. With Apache Bench, we were able to generate web API calls, process streaming event logs with Spark, filter those events and have them saved into Hadoop. At this point we are able to quirey upon the saved data. Overall, we were able to successfully meet all the target tasks listed in part 1.  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m79",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m79"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
